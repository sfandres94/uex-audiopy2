{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cf4a63-c3dc-4630-93ea-aa063505786c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa3c5f-54c4-4e83-bbc5-b6114fd27ae1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b41c60-5347-44c5-9156-18b51c797e2e",
   "metadata": {},
   "source": [
    "# Sesión 4 de SM: Procesamiento de audio con Python <img src=\"imgs/logo_uex.png\" alt=\"missing\" width=22>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d39c8-ff80-4c68-82c1-607dff42c3df",
   "metadata": {},
   "source": [
    "Práctica desarrollada por Andres J. Sanchez-Fernandez (sfandres@unex.es) y Juan M. Haut (juanmariohaut@unex.es) para la asignatura Sistemas Multimedia de la Universidad de Extremadura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab24a2cc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcceb39",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e150fd1a-24ce-4288-9182-687a738723d0",
   "metadata": {},
   "source": [
    "## Organización de la clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e7724",
   "metadata": {},
   "source": [
    "Fecha de la sesión planificada: 05/03/2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2465e9-6a9d-4635-bb9f-c6adaf54b3e6",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Turno</th>\n",
    "    <th>Tiempo (')</th>\n",
    "    <th>Tarea</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Profesor</td>\n",
    "    <td>10</td>\n",
    "    <td>Introducir el contenido de este notebook.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Alumnos</td>\n",
    "    <td>20</td>\n",
    "    <td>Acceder al <a href=\"https://github.com/sfandres94/uex-audiopy2\">GitHub</a> de la práctica y leer detenidamente todos los conceptos que se explican.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Alumnos</td>\n",
    "    <td>&#8734;</td>\n",
    "    <td>Realizar el ejercicio de clase de análisis y procesamiento de ondas de audio con Python3.</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9767c8b1-9aca-4614-a96b-ca11c8d5ed87",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c33cd-271a-4938-952e-8f9166e0a087",
   "metadata": {},
   "source": [
    "Los objetivos de esta práctica son los siguientes:\n",
    "<ol>\n",
    "    <li>Entender lo que es una <b>onda de sonido</b> y cómo se realiza el <b>proceso de adquisición</b> de la misma.</li>\n",
    "    <li>Comprender la importancia de los conceptos básicos que caracterizan una onda:\n",
    "        <ul>\n",
    "            <li>La <b>frecuencia de muestreo</b> (<em>sample rate</em>).</li>\n",
    "            <li>La <b>profundidad de bits</b> (<em>bit depth</em>).</li>\n",
    "            <li>El <b>ancho de banda</b> (<em>bandwidth</em>).</li>\n",
    "            <li>La <b>tasa de bits</b> (<em>bitrate</em>).</li>\n",
    "        </ul>\n",
    "    <li>Conocer la teoría de muestreo de Nyquist y el problema de <em>Aliasing</em>.</li>\n",
    "    <li>Conocer la diferencia entre gráfica de onda en el <b>dominio del tiempo</b> vs <b>de la frecuencia</b> (Transformada de Fourier).</li>\n",
    "    <li>Aprender el <b>concepto de energía del espectrograma</b> y realizar la <b>compresión de audio</b> en base al mismo.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa804d0-43d1-4351-a904-277d7d2c9473",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bibliografía consultada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d212053-5c8a-4130-a743-6ec26e0f2374",
   "metadata": {},
   "source": [
    "Información consultada para el desarrollo de esta práctica:\n",
    "<ul>\n",
    "    <li><em>RouteNote Blog: Understanding sample rates in digital audio by Connor Edney</em> <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Link]</a></li>\n",
    "    <li><em>MiniTool: What Is Audio Sample Rate & How to Change Sample Rate of Audio by Cora</em> <a href=\"https://videoconvert.minitool.com/video-converter/audio-sample-rate.html\">[Link]</a></li>\n",
    "    <li>Repositorios de Github:\n",
    "        <ul>\n",
    "            <li>Cómo graficar espectrogramas de Audios en Python <a href=\"https://www.kaggle.com/code/joeportilla/c-mo-graficar-espectrogramas-de-audios-en-python/notebook\">[Link]</a></li>\n",
    "            <li><em>Simple audio compression with Python</em> <a href=\"https://github.com/jmpion/simple-audio-compression-with-python/blob/master/simple-audio-compression.ipynb\">[Link]</a></li>\n",
    "        </ul>\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4a962-ad3c-49fe-8d6f-7bba0fd78487",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070a363-e94a-4ab6-af7d-dd7f4b34faae",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ce913-726f-462f-b0a8-28ebd00ebb32",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [Práctica anterior] Primeros pasos con audio: sonido mono vs estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f092b27",
   "metadata": {},
   "source": [
    "<center><img src=\"imgs/mono_vs_stereo_diagram.jpg\" alt=\"missing\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0854a2-eee0-454b-aa3f-49537c756216",
   "metadata": {},
   "source": [
    "### Importar librerías y módulos de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62d0544-2df1-48d4-af1b-90f52f848870",
   "metadata": {},
   "source": [
    "<b>Nota</b>: Estas no son las únicas librerías de Python con las que se pueden trabajar para el procesamiento de archivos de audio (otro ejemplo podría ser <a href=\"https://librosa.org/doc/latest/index.html\">Librosa</a>). Si alguien está familiarizado con otras librerías puede utilizarlas.\n",
    "\n",
    "Importamos las librerías/módulos específicos de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb99414-5ac1-4359-9e85-bac6a33d9ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion.\n",
    "# import librosa\n",
    "from scipy.io import wavfile\n",
    "import IPython\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362e5601-4bd0-4600-adf3-ea7aa9bd4df7",
   "metadata": {},
   "source": [
    "### Especificar directorios de entrada y salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6d5954-df9f-4459-8be6-348034f66a24",
   "metadata": {},
   "source": [
    "Aquí definimos los directorios donde guardaremos los audios con los que vamos a trabajar, así como dónde se van a guardar aquellos que generamos a lo largo de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b7e67a-e4c2-4ff4-b06d-7ccee980abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios que usaremos.\n",
    "cwd = os.getcwd()\n",
    "audio_input_path = os.path.join(cwd, os.path.join('audio', '_input'))  # cambiar '_input' por 'examples'\n",
    "audio_output_path = os.path.join(cwd, os.path.join('audio', '_output'))\n",
    "print(f'Directorio con los audios de entrada: {audio_input_path}')\n",
    "print(f'Directorio donde guardaremos los audios generados: {audio_output_path}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5eb3d-e688-421c-8471-e1b3e21422c8",
   "metadata": {},
   "source": [
    "### Cargar el archivo de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742688e-a8d1-4dc9-ba01-20ca1a68fee3",
   "metadata": {},
   "source": [
    "Diferencias entre formatos de archivo para almacenar audio digital.\n",
    "\n",
    "<ul>\n",
    "    <li><b>.wav</b>: Archivo de audio sin comprimir (máxima calidad y gran tamaño de archivo). Típicamente utilizado en edición de audio debido a su fidelidad.</li>\n",
    "    <li><b>.mp3</b> (por ejemplo): Archivo de audio comprimido (con pérdidas pero menor tamaño). Ampliamente usado.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab6aa4-b115-4810-bf74-b2c3b7e17492",
   "metadata": {},
   "source": [
    "Cargamos el archivo de audio .wav en este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d48db-b430-41cd-b051-7af0c158fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el archivo de audio.\n",
    "filename = os.path.join(audio_input_path, 'sample1_stereo.wav')\n",
    "# audio_data, sample_rate = librosa.load(filename, sr=None, mono=False)\n",
    "sample_rate, audio_data = wavfile.read(filename)\n",
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea236d4b-58df-4166-a216-b89d57837811",
   "metadata": {},
   "source": [
    "Vamos a escucharlo. Para que esto se haga correctamente, hay que indicarle la frecuencia de muestreo (veremos más adelante qué es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d992b3-1603-464b-aab9-dab4eab91bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data.T, rate=sample_rate) # .T se pasa únicamente si es audio estéreo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f174b8d3-07da-4dd2-9a54-adcf2d30c1fc",
   "metadata": {},
   "source": [
    "### Mostrar principales características de la onda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a0ee8-c143-467d-8e42-0d043e830e79",
   "metadata": {},
   "source": [
    "Vamos a mostrar la información. Nota: es audio estereo (dos canales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ddf9c-9224-49a1-9884-2eca1644f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar informacion (sonido estéreo).\n",
    "print('Datos de audio (estereo):')\n",
    "print(f'- Tamaño:     {audio_data.shape}')\n",
    "print(f'- 1º canal:   {audio_data[:5, 0]}...')\n",
    "print(f'- 2º canal:   {audio_data[:5, 1]}...')\n",
    "print(f'- Resolucion: {type(audio_data[0,0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22329eff-3797-4dcf-8c69-b4698089eff4",
   "metadata": {},
   "source": [
    "Ahora, por simplificación, vamos a calcular la media por canal para obtener un sonido mono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436e3d0-2e7a-48e7-90d9-cd78a117d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a mono mediante la media por canal (simplificacion).\n",
    "new_data_mono = audio_data.mean(axis=1)  # Column-wise.\n",
    "print('Nuevos datos de audio (mono):')\n",
    "print(f'- Nuevo tamaño: {new_data_mono.shape}')\n",
    "print(f'- Canal unico:  {new_data_mono[:5]}...')\n",
    "\n",
    "# Mantenemos la misma resolucion que antes.\n",
    "new_data_mono = new_data_mono.astype(np.int16)\n",
    "print(f'- Resolucion:   {type(new_data_mono[0])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da0076d-bcb4-47d8-a15d-a3323726fc60",
   "metadata": {},
   "source": [
    "Vamos a guardarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e886f38-dfca-4b4a-9ac0-45a201f178c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el archivo mono a un fichero de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, 'sample1_mono.wav'),\n",
    "    rate=sample_rate,\n",
    "    data=new_data_mono\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26593d8-998f-452b-836d-11ed8425bcf9",
   "metadata": {},
   "source": [
    "Vamos a escucharlo de nuevo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fccd6d-ed00-4598-a249-b3a29210cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_data_mono, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860daa53-6e80-4b79-9f23-e9dbfb6cb123",
   "metadata": {},
   "source": [
    " Se nota que ahora es sonido mono (sobre todo si utilizais cascos).\n",
    "\n",
    "<ul>\n",
    "    <li><b>Mono</b>: se escucha lo mismo por el auricular derecho que por el izquierdo.</li>\n",
    "    <li><b>Estéreo</b>: no se escucha el mismo sonido por ambos canales, sino que se notan variaciones entre los dos.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecee678-b877-4370-847f-1d08e56ecf12",
   "metadata": {},
   "source": [
    "Vamos a ver las diferencias en tamaño de cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642e5d2-6237-46bf-a8c6-63268c6da8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh audio/_input/sample1_stereo.wav\n",
    "!ls -sh audio/_output/sample1_mono.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd488773-2466-4ba0-ae06-ffdd5c35daf2",
   "metadata": {},
   "source": [
    "Como podemos ver el tamaño se ha reducido a la mitad (manteniendo el la frecuencia de muestreo). Mostramos por pantalla la frecuencia de muestreo (*sample rate*) del archivo de audio: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f73f4-1790-49eb-8be9-07704a7bfa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Frecuencia de muestreo (sample rate): {sample_rate/1000} kHz\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416c9b4-9e29-4d5a-9d8c-49dac76f9ada",
   "metadata": {},
   "source": [
    "Muy bien la diferencia entre sonido estéreo y mono pero:\n",
    "\n",
    "*¿cómo se adquiere esta onda de audio?*, *¿qué significa esta frecuencia de muestreo?*, *¿para que sirve la transformada de Fourier?*, *¿para qué queremos comprimir una onda?*, *etc*.\n",
    "\n",
    "Todo esto y más lo veremos a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfc401-401c-4cb1-8b08-b087611f9e6c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72e076-e02f-4e3a-9058-2d7dd6a0b9b5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a02523-a48c-47bd-acf6-f4a3b986ef58",
   "metadata": {},
   "source": [
    "## [Nuevo] Teoría: Toma de muestras de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ccb787-64bb-4214-8d27-d0c0f55d61b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Definición de muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b95afc4-0746-4f41-b440-77d56898b389",
   "metadata": {},
   "source": [
    "Una muestra es una <b>medición instantánea de una onda sonora</b>: una medida de la amplitud de la onda (intensidad de la señal).\n",
    "\n",
    "Un sistema digital, como una interfaz de audio, toma miles de muestras individuales que registran la amplitud de la onda sonora (cambios en la presión del aire) para reconstruirla digitalmente.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/wavecycle.jpg\"\n",
    "         alt=\"missing\"\n",
    "         width=350>\n",
    "    <figcaption><em><b>Figura</b>: Ejemplo de una onda sonora simplificada <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Ref]</a>.</em></figcaption>\n",
    "</figure>\n",
    "\n",
    "Las ondas sonoras son ondas continuas y están formadas por ciclos de onda individuales. Por tanto, <b>una muestra es una medición de la amplitud de un ciclo de onda individual</b>.\n",
    "\n",
    "Entonces, nuestra interfaz puede convertir la onda sonora en datos binarios, interpretables por nuestro ordenador. Ahora bien, ¿cada cuánto tomamos una muestra?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0c555-c52f-4683-a5fb-d3ee5c9cb60e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Frecuencia de muestreo (*sample rate*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6d5922-351e-4954-9f63-36a05f5652e0",
   "metadata": {},
   "source": [
    "#### Definición"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f8376-ab0c-4994-bf08-332f36888e9d",
   "metadata": {},
   "source": [
    "La frecuencia de muestreo equivale al <b>número de muestras que tomamos por segundo</b> y, por tanto, a la velocidad a la que lo hacemos.\n",
    "\n",
    "En la práctica, necesitamos tomar miles de muestras de nuestra grabación por segundo si queremos que nuestra señal digital suene fiel a nuestra onda sonora original.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/sample_rate.jpg\"\n",
    "         alt=\"missing\"\n",
    "         width=500>\n",
    "    <figcaption><em><b>Figura</b>: Explicación visual de la frecuencia de muestreo de una onda de audio. En el primer ejemplo (A), el resultado digital es deficiente\n",
    "        porque las muestras no son lo bastante frecuentes. En el segundo (B), el resultado es mucho mejor y más suave. Ahora bien, es en el tercer ejemplo (C) donde el \n",
    "        resultado digital es tan suave como el audio original al tomarse suficientes muestras <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Ref]</a>.</em>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "A mayor frecuencia de muestreo, capturamos mayor cantidad de detalles de la onda original.\n",
    "\n",
    "La unidad de la frecuencia de muestreo es el Hercio (Hz), que equivale a un periodo de muestreo T = 1s, aunque normalmente se utiliza la unidad derivada kHz (1 kHz = 1 000 Hz)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233b363-e475-41ad-ab83-a4f29dd6476b",
   "metadata": {},
   "source": [
    "#### Valores más comunes de frecuencia de muestreo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7f30f-8c6f-4bd6-b517-00f2dbd6c136",
   "metadata": {},
   "source": [
    "Una de las frecuencias de muestreo de audio **más común actualmente es de 44,1 kHz**, esto significa que se toman **44 100 muestras de audio por segundo**. Las más habituales son:\n",
    "<ul>\n",
    "    <li>8 kHz (8 000 muestras/s) es la frecuencia de muestreo de audio utilizada por los teléfonos, ya que es suficiente para el habla humana.</li>\n",
    "    <li>32 kHz es ampliamente utilizada por las videocámaras digitales MiniDV, DAT, cintas de vídeo, etc.</li>\n",
    "    <li>44,1 kHz es la frecuencia de muestreo de audio estándar para el audio de CD, y también se utiliza para el audio MPEG-1.</li>\n",
    "    <li>48 kHz es la frecuencia de muestreo que suelen utilizar los equipos de vídeo digital, DVD, TV digital, películas y la mayoría de los equipos de audio profesionales.</li>\n",
    "    <li>50 kHz es la frecuencia de muestreo utilizada principalmente por los grabadores digitales comerciales.</li>\n",
    "    <li>88,2 kHz es la frecuencia de muestreo utilizada por algunos equipos de grabación profesionales cuando se apunta a un CD para realizar grabaciones de alta resolución.</li>\n",
    "    <li>96 kHz es el doble del estándar de 48 kHz y se utiliza principalmente en DVD-Audio, pistas de audio de Blu-ray Disc, pistas de audio de DVD de alta definición, etc. Y también está disponible en algunos equipos profesionales de grabación y producción de audio.</li>\n",
    "    <li>192 kHz empleada principalmente en Hi-Res audio junto con la de 96.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee0a870-a46e-4f8a-a416-e24915b72dc7",
   "metadata": {},
   "source": [
    "#### Pregunta sencilla: a mayor frecuencia de muestreo, ¿mayor calidad?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be4594-ffc8-4938-8b76-1807353bd03c",
   "metadata": {},
   "source": [
    "La solución es también sencilla: **¡Sí!**\n",
    "\n",
    "Al aumentar el número de muestras que se toman por segundo, tenemos una mayor resolución, y con ello una mayor calidad del audio.\n",
    "\n",
    "Sin embargo, no todo es bueno: Al grabar con una frecuencia de muestreo más alta, se crea un archivo de audio también mayor. Es decir, como se toman más muestras, se necesita más espacio en disco para almacenarlas y un procesador con mayor potencia para su procesamiento.\n",
    "\n",
    "Ya no es solo el mayor espacio ocupado en disco, sino que un archivo de audio grande es contraproducente para transmitirlo por internet, por ejemplo, en plataformas de streaming tales como Spotify, Amazon Music, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ecb9d-88d0-4220-a2f4-30d163d0df4c",
   "metadata": {},
   "source": [
    "#### Caso real: ¿A qué valor fijamos la frecuencia de muestreo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba9c1b-dd0c-4c5f-a5ea-26676d35d663",
   "metadata": {},
   "source": [
    "Posible respuesta: <b>Teorema de muestreo de Nyquist-Shannon</b>.\n",
    "\n",
    "La teoría de Nyquist establece que *necesitamos una frecuencia de muestreo igual al doble de la frecuencia más alta de una señal para capturar todas las frecuencias de la misma*.\n",
    "\n",
    "Este hecho se debe a que un ciclo de onda singular siempre tiene un valor de amplitud negativo y otro positivo. Estos valores son la medida de la intensidad de la señal de los ciclos (amplitud). Y para hallar la longitud de onda de cada ciclo de onda---que determina sus frecuencias---se deben muestrear las amplitudes positiva y negativa de cada ciclo.\n",
    "\n",
    "En consecuencia, <b>debemos muestrear cada ciclo dos veces (como mínimo)</b> si queremos que nuestra señal digital tenga la frecuencia correcta.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/nyquist.png\"\n",
    "         alt=\"missing\"\n",
    "         width=450>\n",
    "    <figcaption><em><b>Figura</b>: Onda sonora muestreada según el teorema de Nyquist <a href=\"https://www.homestudioproductions.com/frecuencia-de-muestreo-profundidad-de-bits-que-es/\">[Ref]</a>.</em>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971d3fd-99ed-4a3e-9870-c437aa83dd25",
   "metadata": {},
   "source": [
    "#### Cuando el muestreo sale mal: *Aliasing*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129594eb-68af-4c90-8665-a19596bd3734",
   "metadata": {},
   "source": [
    "La teoría de muestreo de Nyquist nos dice que tomar menos de 2 muestras por ciclo conduce a una reconstrucción digital incorrecta de nuestra señal: un \"alias\" no deseado del original. Por tanto, se denomina *aliasing*, o solapamiento, al <b>efecto que causa que señales continuas distintas sean indistinguibles cuando se muestrean digitalmente a causa de una frecuencia de muestreo demasiado baja</b>. Cuando esto sucede, la señal original no puede ser reconstruida de forma unívoca a partir de la señal digital.\n",
    "\n",
    "<p style=\"border-width:1.25px; border-style:solid; border-color:#0000FF; background-color:#EEEEEE; padding:1em;\">\n",
    "    <b>Ejemplo:</b> Vamos a muestrear la siguiente señal siguiendo el criterio de Nyquist:\n",
    "</p>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/nyquist_sample_rate_perfect.jpg\"\n",
    "         alt=\"missing\"\n",
    "         width=400>\n",
    "    <figcaption><em><b>Figura</b>: Onda sonora muestreada con una frecuencia de muestro que cumple con el teorema de Nyquist <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Ref]</a>.</em>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "<p style=\"border-width:1.25px; border-style:solid; border-color:#0000FF; background-color:#EEEEEE; padding:1em;\">\n",
    "    Podemos observar como la señal reconstruida (3) es similar a la original (1) ya que hemos tomado suficientes muestras (2).<br><br>\n",
    "    Ahora bien, si aumentamos la frecuencia de la señal original sin aumentar el número de muestras ocurre lo siguiente:\n",
    "</p>\n",
    "    \n",
    "<figure>\n",
    "    <img src=\"imgs/too_low_a_sample_rate_poor.jpg\"\n",
    "         alt=\"missing\"\n",
    "         width=400>\n",
    "    <figcaption><em><b>Figura</b>: Onda sonora muestreada con una frecuencia de muestro menor que la necesaria según el teorema de Nyquist <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Ref]</a>.</em>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "<p style=\"border-width:1.25px; border-style:solid; border-color:#0000FF; background-color:#EEEEEE; padding:1em;\">\n",
    "    Ahora podemos ver que, a pesar de que la nueva señal (4) es muy diferente a la que vimos anteriormente (1), el resultado de la señal reconstruida (6) es el mismo que en el caso anterior (3).<br><br>\n",
    "    <b>Entonces concluímos que se ha producido <i>aliasing</i>.</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f56a64-af10-4479-b44f-6df1bb739f3a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3b496-7e6e-4061-ac24-43b545392c9a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d458ded-350d-463b-a4a8-53d6489004e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mas teoría: Características de grabación de audio digital"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28217dd-14be-4cd1-9aa1-bacfe22f3844",
   "metadata": {},
   "source": [
    "### Profundidad de bits (*bit depth*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29741d16-cbf6-4742-9f9c-1224f64a69bd",
   "metadata": {},
   "source": [
    "Una vez que hemos capturado la onda como se ha explicado, hay que almacenar la información en forma de bits.\n",
    "\n",
    "La profundidad de bits determina <b>cuántos bits disponibles hay para medir la onda sonora</b> en primer lugar, y luego para que almacenemos nuestras muestras en bytes digitales.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/adc.jpg\"\n",
    "         alt=\"missing\"\n",
    "         width=500>\n",
    "    <figcaption><em><b>Figura</b>: Conversión Analógica Digital (ADC) <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Ref]</a>.</em>\n",
    "    </figcaption\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e18232-ef5c-4dea-a6d1-7d09d8ea4c02",
   "metadata": {},
   "source": [
    "### Ancho de banda (*bandwidth*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a48d1-d4f5-4e6c-8896-1c52444d3593",
   "metadata": {},
   "source": [
    "En otras palabras, <b>la profundidad de bits y la frecuencia de muestreo trabajan juntas para darnos el ancho de banda total de nuestra grabación digital</b>.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Profundidad de bits (bit depth)}+\\text{frecuencia de muestreo (sample rate)}=\\text{ancho de banda (bandwidth)}\n",
    "\\end{equation}\n",
    "\n",
    "Esto significa que el ancho de banda total <b>define la precisión de nuestra señal digital con respecto a la grabación original</b>. Más ancho de banda implica una reproducción más exacta.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/bit_depth.jpg\"\n",
    "         alt=\"missing\"\n",
    "         width=600>\n",
    "    <figcaption><em><b>Figura</b>: La frecuencia de muestreo y la profundidad de bits forman el ancho de banda de audio total. La cantidad de bits disponibles se corresponde con el número de valores de amplitud digital a los que podemos asignar nuestras muestras <a href=\"https://routenote.com/blog/what-is-sample-rate-in-audio/\">[Ref]</a>.</em>\n",
    "    </figcaption\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a82d6f-a8f9-44e6-8b59-9b6a152a6dc0",
   "metadata": {},
   "source": [
    "### Suele llevar a confusión: Frecuencia de muestreo vs tasa de bits (*bitrate*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d6e7ae-6340-4408-9b20-ceb0d7b1dc53",
   "metadata": {},
   "source": [
    "Como se ha explicado, la frecuencia de muestreo representa cuántas muestras de la onda sonora original tomamos por segundo. Aunque tenemos otra variable también: el flujo o tasa de bits, que determina el tamaño del archivo de audio digital. La tasa de bits es un <b>cálculo matemático del tamaño de los archivos digitales en megabytes por segundo</b> (Mbps)---no confundir con la profundidad de bits.\n",
    "\n",
    "Para calcular la tasa de bits de tu grabación digital, puedes utilizar el siguiente cálculo:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{bitrate}\\;(Mbps) = f_s \\cdot f_d \\cdot n_c\n",
    "\\end{equation}\n",
    "\n",
    "donde $f_s$ es la frecuencia de muestreo, $f_d$ es la profundidad de bits y $n_c$ es el número de canales de la grabación.\n",
    "\n",
    "En base a todo esto, se puede decir que la tasa de bits determina el <b>número de bits que el ordenador debe procesar por segundo para reproducir la grabación de audio digital de la forma prevista</b>.\n",
    "\n",
    "<p style=\"border-width:1.25px; border-style:solid; border-color:#0000FF; background-color:#EEEEEE; padding:1em;\">\n",
    "    <b>Ejemplo:</b> Supongamos que grabamos un riff de guitarra con una frecuencia de muestreo de 44,1 kHz y una profundidad de bits de 24 bits. Entonces tendríamos una tasa de bits de:<br><br>\n",
    "    $44\\,100\\,(Hz)\\cdot 24\\,(bits) \\cdot 1\\,canal = 1\\,058\\,400\\,(bps) = 1,1\\,(Mbps)$<br><br>\n",
    "    Después de calcular la tasa de bits de tu grabación, multiplícala por el número de segundos de tu grabación si quieres saber el tamaño total del archivo. Digamos que grabamos durante 20 segundos, nos quedaría:<br><br>\n",
    "    $1,1\\,(Mbps) \\cdot 20\\,(s) = 22\\,Mb$\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc26c923-4a25-4751-92ac-3b63809649f9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86ed24-445c-4091-acc0-c31df11e8a08",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa4d8b-779e-4bb7-8566-c7678517e9ca",
   "metadata": {},
   "source": [
    "## Práctica: Compresión de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697776dc-eb08-4839-98f2-818f3c9404c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cargar audios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398394e4-9e8e-4f1d-9c16-0e2723ca8b19",
   "metadata": {},
   "source": [
    "Vamos a cargar otros dos archivos de audio adquiridos a distintas frecuencias de muestreo: 48 y 24 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d0e95-50ed-45e3-8e67-b0330ee41644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los archivos de audio.\n",
    "sample_rate_48, audio_data_48 = wavfile.read(filename=os.path.join(audio_input_path, 'sample_48kHz.wav'))\n",
    "sample_rate_24, audio_data_24 = wavfile.read(filename=os.path.join(audio_input_path, 'sample_24kHz.wav'))\n",
    "\n",
    "# Otro ejemplo sería: audio_data, sample_rate = librosa.load(filename)\n",
    "\n",
    "print(f'{audio_data_48.shape}\\n')  # Audio mono\n",
    "print(f'{audio_data_24.shape}\\n')  # Audio mono"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01af9a-d6dd-418f-9c60-f554730c2e71",
   "metadata": {},
   "source": [
    "Vamos a escuchar los audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179de5c-43f9-479d-a637-dfab532c1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data_48, rate=sample_rate_48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90744117-c615-4c10-8297-d1b8d1a22812",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(audio_data_24, rate=sample_rate_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2acd8-d7e2-4964-b845-bea41fcbc563",
   "metadata": {},
   "source": [
    "Tenemos los siguientes tamaños de archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd2ae5-6687-4180-b567-204440ba2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh audio/_input/sample_48kHz.wav\n",
    "!ls -sh audio/_input/sample_24kHz.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9898dc56-7b25-4502-91fe-9fb099f54f6e",
   "metadata": {},
   "source": [
    "Como se puede ver y es lógico, la frecuencia de muestreo también afecta al tamaño del archivo de audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ef8e88-3fb2-4b47-9c8c-0bf847583d0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Gráficas características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73313fe9-e680-41fe-87e3-00c977afec57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dominio del tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ef2a6-1cc9-4067-8cf3-2873ca949fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ampl_values_48 = len(audio_data_48)\n",
    "ampl_values_24 = len(audio_data_24)\n",
    "print(f'Número de muestras del audio con fs=48 kHz (valores de amplitud): {ampl_values_48}')\n",
    "print(f'Número de muestras del audio con fs=24 kHz (valores de amplitud): {ampl_values_24}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed67d2-0ef7-4488-9baa-f866a170e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el array para el eje x que representa el tiempo de la grabación.\n",
    "# Tiene la forma: np.arange(Vi, Vf, P). Explicado a continuación.\n",
    "t1 = np.arange(0, ampl_values_48/sample_rate_48, 1/sample_rate_48)\n",
    "t2 = np.arange(0, ampl_values_24/sample_rate_24, 1/sample_rate_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ccfda-b652-43ed-aea4-49c274629eba",
   "metadata": {},
   "source": [
    "Vamos a construir el eje x con un array que tenga como:\n",
    "<ul>\n",
    "    <li>Valor inicial ($V_i$): $$V_i=0\\;s$$</li><br>\n",
    "    <li>Valor final ($V_f$): $$V_f = \\frac{N}{f_s}$$<br> donde $N$ representa el número total de muestras (valores de amplitud) y $f_s$ es la frecuencia de muestreo en Hz (número total de muestras capturadas por segundo). Esto nos da la duración total de la grabación en segundos.</li><br>\n",
    "    <li>Paso o <i>step</i> ($P$): $$P=T=\\frac{1}{f_s}$$<br>donde $T$ se refiere al periodo de la señal, es decir, el tiempo transcurrido entre dos puntos equivalentes de la onda.</li><br>\n",
    "<ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397999c-2311-4ebb-86c9-ed26347a3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282e20a-8d9e-4f8c-8d18-d3b9b791bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la figura.\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# Solo mostramos las primeras 50 muestras de amplitud (por claridad).\n",
    "end = 50\n",
    "\n",
    "# Señal a 48 kHz.\n",
    "ax[0].plot(t1[:end], audio_data_48[:end], marker='X')\n",
    "ax[0].set_title(f'Audio en el dominio del tiempo muestreado a {sample_rate_48} Hz')\n",
    "ax[0].set_ylabel('Amplitud')\n",
    "ax[0].grid(True)\n",
    "\n",
    "# Señal a 24 kHz.\n",
    "# Utilizamos ratio para ajustar el eje x de ambas gráficas\n",
    "# ya que la fs es menor en esta señal.\n",
    "ratio = sample_rate_48 / sample_rate_24  \n",
    "ax[1].plot(t2[:int(end/ratio)], audio_data_24[:int(end/ratio)], c='tab:red', marker='X')\n",
    "ax[1].set_title(f'Audio en el dominio del tiempo muestreado a {sample_rate_24} Hz')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Amplitud')\n",
    "ax[1].grid(True)\n",
    "\n",
    "# Mostramos la figura.\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec25dd0-ee57-4904-b07f-85091adfc25a",
   "metadata": {},
   "source": [
    "Cada cruz que se ve en las gráficas representa una muestra recogida del audio. Podemos ver que la primera onda tiene un mayor número de muestras recogidas para el mismo periodo de tiempo (mismos valores en el eje x). Por tanto, la primera onda tiene también una precisión mayor que la segunda al tener el doble de frecuencia de muestreo, siendo entonces más fiel a la onda sonora original (fuente)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce7fab-53f9-4ad8-b088-1829fdc5e596",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dominio de la frecuencia: Transformada de Fourier (FFT) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebd491-265f-4e26-900e-1befadbc75d4",
   "metadata": {},
   "source": [
    "##### Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a33eb2-6b99-463a-9fd8-b86f36bf4cf8",
   "metadata": {},
   "source": [
    "Vamos a descomponer la señal en vez de en el dominio del tiempo (eje x: tiempo en segundos) en el dominio de la frecuencia (eje x: frecuencia en Hz). A continuación se presentan dos ejemplos animados del funcionamiento de la Transformada de Fourier:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32665475-a9e0-4aa3-a8ba-68f1495168e9",
   "metadata": {},
   "source": [
    "<figure>\n",
    "    <img src=\"imgs/Fourier_1.gif\"\n",
    "         alt=\"missing\"\n",
    "         width=400>\n",
    "    <figcaption><em><b>Figura animada</b>: Ejemplo 1 de la transformada de Fourier <a href=\"https://en.wikipedia.org/wiki/File:Fourier_transform_time_and_frequency_domains.gif\">[Ref]</a>.</em>\n",
    "    </figcaption\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/Fourier_2.gif\"\n",
    "         alt=\"missing\"\n",
    "         width=450>\n",
    "    <figcaption><em><b>Figura animada</b>: Ejemplo 2 de la transformada de Fourier <a href=\"https://commons.wikimedia.org/wiki/File:Fourier_synthesis_square_wave_animated.gif\">[Ref]</a>.</em>\n",
    "    </figcaption\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4ff851-fbb8-410a-94ec-3c54cc35ff0c",
   "metadata": {},
   "source": [
    "##### Análisis de Fourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb9b0f6-d9c0-4b9f-8bc5-8a2e535b530e",
   "metadata": {},
   "source": [
    "La \"Transformación rápida de Fourier\" (FFT para abreviar) <b>descompone una señal en sus componentes espectrales individuales, proporcionando información sobre su composición.</b> Este es un método importante de medición en la tecnología de audio.\n",
    "\n",
    "<figure>\n",
    "    <img src=\"imgs/Fourier_3.png\"\n",
    "         alt=\"missing\"\n",
    "         width=450>\n",
    "    <figcaption><em><b>Figura</b>: Transformada de Fourier <a href=\"https://luisgarciamillan.es/transformada-de-fourier/\">[Ref]</a>.</em>\n",
    "    </figcaption\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f027f-d9d3-4067-bd59-53ad94cb1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La longitud del array de datos y el\n",
    "# sample rate (frecuencia de muestreo).\n",
    "n = len(audio_data_48)\n",
    "Fs = sample_rate_48\n",
    "\n",
    "# Working with stereo audio, there are two channels in the audio data.\n",
    "# Let's retrieve each channel seperately:\n",
    "# ch1 = np.array([data[i][0] for i in range(n)]) #channel 1\n",
    "# ch2 = np.array([data[i][1] for i in range(n)]) #channel 2\n",
    "# We can then perform a Fourier analysis on the first\n",
    "# channel to see what the spectrum looks like.\n",
    "\n",
    "# Calculando la Transformada Rapida de Fourier (FFT) en audio mono.\n",
    "ch_Fourier = np.fft.fft(audio_data_48)  # ch1\n",
    "\n",
    "# Solo miramos frecuencia por debajo de Fs/2\n",
    "# (Nyquist-Shannon) --> Spectrum.\n",
    "abs_ch_Fourier = np.absolute(ch_Fourier[:n//2])\n",
    "\n",
    "# Graficamos.\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud', labelpad=10)\n",
    "plt.xlabel('$f$ (Hz)', labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc6160e-6042-4d56-9378-2650863d30fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Energia del espectrograma y frecuencia de corte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4eecf4-e70a-4abb-a750-c66333e0a808",
   "metadata": {},
   "source": [
    "Ahora vamos a definir una frecuencia umbral $f_0$ por la que cortar el espectro, es decir, <b>solo nos quedaremos con aquellas frecuencias que esten por debajo de este valor para el archivo de audio comprimido</b>.\n",
    "\n",
    "Con este fin, definimos el parámetro <b>epsilon</b> $\\epsilon \\in (0, 1)$ que <b>representa la parte de la energía del espectro que NO conservaremos</b> (la integral con respecto a la frecuencia).\n",
    "\n",
    "En esta práctica, a modo de ejemplo, seleccionamos un $\\epsilon=10^{-5}$ para quitar únicamente una parte, podéis jugar con este valor como queráis para ver el resultado. De manera intuitiva, a medida que aumenta su valor, se mantienen menos frecuencias por lo que la calidad del audio es peor aunque el tamaño del archivo de salida es más reducido. Por lo que tenemos que buscar un buen balance en este sentido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7dd0b-a00c-41bc-882e-effe051fea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos diferentes epsilons: la parte de\n",
    "# la energia del espectro que NO conservamos.\n",
    "eps = [1e-5, .02, .041, .063, .086, .101, .123]\n",
    "\n",
    "# Jugamos con los valores de epsilon (ID VARIANDO ESTE VALOR Y MIRAD LA GRÁFICA).\n",
    "eps = eps[1]\n",
    "print(f'Epsilon: {eps}')\n",
    "\n",
    "# Calculamos el valor de corte para esta energia.\n",
    "thr_spec_energy = (1 - eps) * np.sum(abs_ch_Fourier)\n",
    "print(f'Valor de corte para la energia del espectro: {thr_spec_energy}')\n",
    "\n",
    "# Integral de la frecuencia --> energia del espectro.\n",
    "spec_energy = np.cumsum(abs_ch_Fourier)\n",
    "\n",
    "# Mascara (array booleano) que compara el\n",
    "# valor de corte con la energia del espectro.\n",
    "frequencies_to_remove = thr_spec_energy < spec_energy  \n",
    "print(f'Mascara: {frequencies_to_remove}')\n",
    "\n",
    "# La frecuencia f0 por la que cortamos el espectro.\n",
    "f0 = (len(frequencies_to_remove) - np.sum(frequencies_to_remove)) * (Fs/2) / (n//2)\n",
    "print(f'Frecuencia de corte f0 (Hz): {int(f0)}')\n",
    "\n",
    "# Graficamos.\n",
    "plt.axvline(f0, color='r')\n",
    "plt.plot(np.linspace(0, Fs/2, n//2), abs_ch_Fourier)\n",
    "plt.ylabel('Amplitud')\n",
    "plt.xlabel('$f$ (Hz)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db7b4d-3b0e-41ac-ba45-c262a0b32259",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compresión del archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a532e0-569c-4d2c-9314-7a2b6b366b65",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reducción de la resolución de muestreo (*downsampling*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d8743-dac3-4648-b7de-a235451d85e0",
   "metadata": {},
   "source": [
    "<b>Para reducir el tamaño del archivo de audio</b>, lo que vamos a hacer es aplicar <b><em>downsampling</em></b>. Vamos a definir el factor de <em>downsampling</em> $D$, el cual utilizaremos para quedarnos únicamente con la secuencia de valores ($\\hat{x}$) del audio original ($x$) como sigue:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{x}[i] = x[D\\cdot i]\n",
    "\\end{equation}\n",
    "\n",
    "Esta equación quiere decir que <b>la secuencia de audio resultante estará compuesta por aquellos elementos elementos situados en las posiciones múltiplo de $D$ (<em>slicing</em>)</b>. Para saber qué valor debemos utilizar para el <em>downsampling</em>, una opción es la de calcular $D=\\frac{f_s}{f_0}$, por lo que la nueva frecuencia de muestreo (<em>sample rate</em>) estaría definida por $\\hat{f}_s=\\frac{f_s}{D}$.\n",
    "\n",
    "Gracias a todo este proceso, las frecuencias que constituyen la parte principal del espectro quedarán por debajo de la nueva frecuencia de muestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947f28a-6735-45b8-8e69-b7b15e3e8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los nombres de los audios comprimidos.\n",
    "wav_compressed_file = \"sample_48kHz_compressed.wav\"\n",
    "\n",
    "# Calculamos el factor D de downsampling.\n",
    "D = int(Fs / f0)\n",
    "print(f'Factor de downsampling: {D}')\n",
    "\n",
    "# Obtenemos los nuevos datos (slicing with stride).\n",
    "new_data = audio_data_48[::D]\n",
    "\n",
    "# Escribimos los datos a un archivo de tipo wav.\n",
    "wavfile.write(\n",
    "    filename=os.path.join(audio_output_path, wav_compressed_file),\n",
    "    rate=int(Fs/D),\n",
    "    data=new_data\n",
    ")\n",
    "\n",
    "# Cargamos el nuevo archivo.\n",
    "new_sample_rate, new_audio_data = wavfile.read(filename=os.path.join(audio_output_path, wav_compressed_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf63c5ab-d007-41cb-be82-b5b8b892795b",
   "metadata": {},
   "source": [
    "Vamos a escucharlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906db420-013a-4044-b63f-9ee5b37c7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(new_audio_data, rate=new_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe62086-2113-4535-a224-5cdcdcd00560",
   "metadata": {},
   "source": [
    "Consejo: probad a cambiar la variable `eps` y ejecutar de nuevo las celdas para ir viendo como se deteriora la calidad al aumentar el factor de *downsampling*.\n",
    "\n",
    "Después de la compresión, el tamaño final será menor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47895e7f-add2-4f3a-8084-711c4d443398",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -sh audio/_output/sample_48kHz_compressed.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82478c22-5431-442a-b5e8-070c350d5c24",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Espectrograma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f8b5b-48e3-4281-bd5c-418696f26eb5",
   "metadata": {},
   "source": [
    "El espectrograma es una representación visual que muestra las diferentes variaciones de la frecuencia (eje y) y la intensidad del sonido (color) a lo largo del tiempo (eje x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf989f-da31-420d-abae-5ed780feac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[0].specgram(audio_data_48, NFFT=1024, Fs=sample_rate_48, noverlap=512)\n",
    "ax[0].set_title('Espectograma del audio original')\n",
    "ax[0].set_ylabel('Frecuencia (Hz)')\n",
    "ax[0].grid(True)\n",
    "\n",
    "Pxx, freqs, bins, im = ax[1].specgram(new_audio_data, NFFT=1024, Fs=new_sample_rate, noverlap=512)\n",
    "ax[1].set_title('Espectrograma del audio reducido/comprimido')\n",
    "ax[1].set_xlabel('Tiempo (s)')\n",
    "ax[1].set_ylabel('Frecuencia (Hz)')\n",
    "ax[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3419c4-1dc4-495a-bc98-70aaca6d3a7a",
   "metadata": {},
   "source": [
    "Podemos observar como la resolución se ha reducido, aunque aún se pueden apreciar características similares en ambos espectrogramas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d438d31-0602-4faf-a712-ddf23a317b12",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d15df-aabb-43c0-8f8a-f8203f5b0142",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5a440-6a0c-4c17-b06e-af3fa5fdd979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Ignorar: Codigo para reducir un archivo de audio truncando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fceb041-21ba-4677-b900-89508e99f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input data.\n",
    "# audio_examples_input_path = os.path.join(cwd, os.path.join('audio', 'examples'))\n",
    "# filename = os.path.join(audio_examples_input_path, 'interstellar.wav')\n",
    "# sample_rate_v0, audio_data_v0 = wavfile.read(filename)\n",
    "# print(f'Shape of the input audio data: {audio_data_v0.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6af37-e3dd-48a4-a06e-31c26a38712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Slicing with stride (stereo).\n",
    "# new_data_v0 = audio_data_v0[:10856495//4, :]\n",
    "\n",
    "# # Writing to a wav file.\n",
    "# wavfile.write(\n",
    "#     filename=os.path.join(audio_examples_input_path, 'interstellar2.wav'),\n",
    "#     rate=sample_rate_v0,\n",
    "#     data=new_data_v0\n",
    "# )\n",
    "\n",
    "# # Loading the new audio data.\n",
    "# filename = os.path.join(audio_examples_input_path, 'interstellar2.wav')\n",
    "# sample_rate_v1, audio_data_v1 = wavfile.read(filename)\n",
    "# print(f'Shape of the input audio data min: {audio_data_v1.shape}')\n",
    "# print(f'Reduction (%): {int((len(audio_data_v0)-len(audio_data_v1))*100/len(audio_data_v0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ed04da-facb-4723-b970-864ac239d2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython.display.Audio(audio_data_v1.T, rate=sample_rate_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4a944-fadc-4adf-b700-9ad78c02d97a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiopy",
   "language": "python",
   "name": "audiopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
